"""
Script de teste para o Sistema de OrquestraÃ§Ã£o de Agentes
"""

import asyncio
import json
import os
import sys
from datetime import datetime

# Adiciona o diretÃ³rio atual ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from orchestration_system import OrchestrationSystem, OrchestrationWorkflow
from config_utils import ConfigManager


async def test_basic_functionality():
    """Testa funcionalidades bÃ¡sicas do sistema"""
    print("=== Teste de Funcionalidades BÃ¡sicas ===")
    
    # Inicializa sistema
    system = OrchestrationSystem()
    
    try:
        await system.initialize()
        print("âœ“ Sistema inicializado com sucesso")
        
        # Testa status do sistema
        status = system.get_system_status()
        print(f"âœ“ Status do sistema obtido: {status['agents_count']} agentes disponÃ­veis")
        
        # Lista agentes disponÃ­veis
        agents = system.get_available_agents()
        print(f"âœ“ Agentes disponÃ­veis: {len(agents)}")
        for agent in agents:
            print(f"  - {agent['name']}: {agent['description']}")
        
        return system
        
    except Exception as e:
        print(f"âœ— Erro na inicializaÃ§Ã£o: {str(e)}")
        return None


async def test_orchestrator_creation(system):
    """Testa criaÃ§Ã£o de orquestradores"""
    print("\n=== Teste de CriaÃ§Ã£o de Orquestradores ===")
    
    if not system or not system.agents:
        print("âœ— Sistema nÃ£o disponÃ­vel ou sem agentes")
        return False
    
    try:
        # Testa criaÃ§Ã£o de orquestrador sequencial
        agent_names = list(system.agents.keys())[:2]  # Pega os primeiros 2 agentes
        
        orchestrator_name = await system.create_orchestrator(
            name="teste_sequencial",
            pattern="sequential",
            agent_names=agent_names
        )
        print(f"âœ“ Orquestrador sequencial criado: {orchestrator_name}")
        
        # Testa criaÃ§Ã£o de orquestrador concorrente
        orchestrator_name = await system.create_orchestrator(
            name="teste_concorrente",
            pattern="concurrent",
            agent_names=agent_names
        )
        print(f"âœ“ Orquestrador concorrente criado: {orchestrator_name}")
        
        # Lista orquestradores
        orchestrators = system.get_orchestrators()
        print(f"âœ“ Orquestradores criados: {len(orchestrators)}")
        for orch in orchestrators:
            print(f"  - {orch['name']}: {orch['pattern']} com {len(orch['agents'])} agentes")
        
        return True
        
    except Exception as e:
        print(f"âœ— Erro na criaÃ§Ã£o de orquestradores: {str(e)}")
        return False


async def test_orchestration_execution(system):
    """Testa execuÃ§Ã£o de orquestraÃ§Ãµes"""
    print("\n=== Teste de ExecuÃ§Ã£o de OrquestraÃ§Ãµes ===")
    
    if not system:
        print("âœ— Sistema nÃ£o disponÃ­vel")
        return False
    
    # Verifica se hÃ¡ chave API configurada
    config_manager = ConfigManager()
    llm_config = config_manager.get_llm_config()
    
    if not llm_config.api_key:
        print("âš  Chave API nÃ£o configurada - simulando execuÃ§Ã£o")
        return await simulate_orchestration_execution(system)
    
    try:
        # Testa orquestraÃ§Ã£o sequencial
        result = await system.execute_orchestration(
            orchestrator_name="teste_sequencial",
            task="Analise o mercado de tecnologia e crie um relatÃ³rio resumido",
            context={"formato": "resumo executivo"}
        )
        
        print(f"âœ“ OrquestraÃ§Ã£o sequencial executada:")
        print(f"  - Sucesso: {result.get('success', False)}")
        print(f"  - Tempo: {result.get('execution_time', 0):.2f}s")
        
        if result.get('success'):
            print(f"  - Resultado final disponÃ­vel")
        else:
            print(f"  - Erro: {result.get('error', 'Desconhecido')}")
        
        # Testa orquestraÃ§Ã£o concorrente
        result = await system.execute_orchestration(
            orchestrator_name="teste_concorrente",
            task="Crie ideias para uma campanha de marketing digital",
            context={"pÃºblico": "jovens adultos", "produto": "aplicativo mÃ³vel"}
        )
        
        print(f"âœ“ OrquestraÃ§Ã£o concorrente executada:")
        print(f"  - Sucesso: {result.get('success', False)}")
        print(f"  - Tempo: {result.get('execution_time', 0):.2f}s")
        
        return True
        
    except Exception as e:
        print(f"âœ— Erro na execuÃ§Ã£o de orquestraÃ§Ãµes: {str(e)}")
        return False


async def simulate_orchestration_execution(system):
    """Simula execuÃ§Ã£o de orquestraÃ§Ãµes quando nÃ£o hÃ¡ API key"""
    try:
        # Simula resultado de orquestraÃ§Ã£o sequencial
        print("âœ“ SimulaÃ§Ã£o de orquestraÃ§Ã£o sequencial:")
        print("  - Sucesso: True (simulado)")
        print("  - Tempo: 2.5s (simulado)")
        print("  - Agentes processaram sequencialmente")
        
        # Simula resultado de orquestraÃ§Ã£o concorrente
        print("âœ“ SimulaÃ§Ã£o de orquestraÃ§Ã£o concorrente:")
        print("  - Sucesso: True (simulado)")
        print("  - Tempo: 1.8s (simulado)")
        print("  - Agentes processaram em paralelo")
        
        return True
        
    except Exception as e:
        print(f"âœ— Erro na simulaÃ§Ã£o: {str(e)}")
        return False


async def test_workflow_functionality(system):
    """Testa funcionalidade de workflows"""
    print("\n=== Teste de Workflows ===")
    
    if not system:
        print("âœ— Sistema nÃ£o disponÃ­vel")
        return False
    
    try:
        # Cria gerenciador de workflow
        workflow_manager = OrchestrationWorkflow(system)
        
        # Define um workflow de exemplo
        workflow_steps = [
            {
                "name": "AnÃ¡lise Inicial",
                "orchestrator": "teste_sequencial"
            },
            {
                "name": "GeraÃ§Ã£o de Ideias",
                "orchestrator": "teste_concorrente"
            }
        ]
        
        workflow_manager.define_workflow(
            name="workflow_completo",
            steps=workflow_steps,
            description="Workflow de exemplo com anÃ¡lise e geraÃ§Ã£o de ideias"
        )
        
        print("âœ“ Workflow definido com sucesso")
        
        # Lista workflows
        workflows = workflow_manager.get_workflows()
        print(f"âœ“ Workflows disponÃ­veis: {len(workflows)}")
        for workflow in workflows:
            print(f"  - {workflow['name']}: {len(workflow['steps'])} etapas")
        
        return True
        
    except Exception as e:
        print(f"âœ— Erro no teste de workflows: {str(e)}")
        return False


async def test_metrics_collection(system):
    """Testa coleta de mÃ©tricas"""
    print("\n=== Teste de MÃ©tricas ===")
    
    if not system:
        print("âœ— Sistema nÃ£o disponÃ­vel")
        return False
    
    try:
        # ObtÃ©m mÃ©tricas
        metrics = system.get_metrics()
        
        print("âœ“ MÃ©tricas coletadas:")
        print(f"  - Total de orquestraÃ§Ãµes: {metrics['orchestrations_count']}")
        print(f"  - Sucessos: {metrics['successful_orchestrations']}")
        print(f"  - Falhas: {metrics['failed_orchestrations']}")
        print(f"  - Tempo mÃ©dio: {metrics['average_execution_time']:.2f}s")
        
        if metrics['patterns_usage']:
            print("  - Uso de padrÃµes:")
            for pattern, count in metrics['patterns_usage'].items():
                print(f"    * {pattern}: {count}")
        
        if metrics['agents_usage']:
            print("  - Uso de agentes:")
            for agent, count in metrics['agents_usage'].items():
                print(f"    * {agent}: {count}")
        
        return True
        
    except Exception as e:
        print(f"âœ— Erro na coleta de mÃ©tricas: {str(e)}")
        return False


async def test_configuration():
    """Testa sistema de configuraÃ§Ã£o"""
    print("\n=== Teste de ConfiguraÃ§Ã£o ===")
    
    try:
        # Testa carregamento de configuraÃ§Ã£o
        config_manager = ConfigManager()
        
        print("âœ“ ConfiguraÃ§Ã£o carregada:")
        print(f"  - Provedor LLM: {config_manager.config['llm']['provider']}")
        print(f"  - Modelo: {config_manager.config['llm']['model_name']}")
        print(f"  - PadrÃ£o de orquestraÃ§Ã£o: {config_manager.config['orchestration']['default_pattern']}")
        
        # Testa configuraÃ§Ã£o do LLM
        llm_config = config_manager.get_llm_config()
        print(f"âœ“ ConfiguraÃ§Ã£o LLM obtida: {llm_config.provider}")
        
        # Verifica se hÃ¡ chave API
        if llm_config.api_key:
            print("âœ“ Chave API configurada")
        else:
            print("âš  Chave API nÃ£o configurada (configure OPENAI_API_KEY)")
        
        return True
        
    except Exception as e:
        print(f"âœ— Erro no teste de configuraÃ§Ã£o: {str(e)}")
        return False


async def run_all_tests():
    """Executa todos os testes"""
    print("ğŸš€ Iniciando testes do Sistema de OrquestraÃ§Ã£o de Agentes")
    print("=" * 60)
    
    # Teste de configuraÃ§Ã£o
    config_ok = await test_configuration()
    
    # Teste de funcionalidades bÃ¡sicas
    system = await test_basic_functionality()
    
    if system:
        # Testes que dependem do sistema
        orchestrator_ok = await test_orchestrator_creation(system)
        
        if orchestrator_ok:
            execution_ok = await test_orchestration_execution(system)
            workflow_ok = await test_workflow_functionality(system)
        else:
            execution_ok = workflow_ok = False
        
        metrics_ok = await test_metrics_collection(system)
        
        # Finaliza sistema
        await system.shutdown()
    else:
        orchestrator_ok = execution_ok = workflow_ok = metrics_ok = False
    
    # Resumo dos testes
    print("\n" + "=" * 60)
    print("ğŸ“Š Resumo dos Testes:")
    print(f"âœ“ ConfiguraÃ§Ã£o: {'OK' if config_ok else 'FALHOU'}")
    print(f"âœ“ Funcionalidades BÃ¡sicas: {'OK' if system else 'FALHOU'}")
    print(f"âœ“ CriaÃ§Ã£o de Orquestradores: {'OK' if orchestrator_ok else 'FALHOU'}")
    print(f"âœ“ ExecuÃ§Ã£o de OrquestraÃ§Ãµes: {'OK' if execution_ok else 'FALHOU'}")
    print(f"âœ“ Workflows: {'OK' if workflow_ok else 'FALHOU'}")
    print(f"âœ“ MÃ©tricas: {'OK' if metrics_ok else 'FALHOU'}")
    
    total_tests = 6
    passed_tests = sum([config_ok, bool(system), orchestrator_ok, execution_ok, workflow_ok, metrics_ok])
    
    print(f"\nğŸ¯ Resultado: {passed_tests}/{total_tests} testes passaram")
    
    if passed_tests == total_tests:
        print("ğŸ‰ Todos os testes passaram! Sistema funcionando corretamente.")
    elif passed_tests >= total_tests * 0.8:
        print("âœ… Maioria dos testes passou. Sistema funcional com algumas limitaÃ§Ãµes.")
    else:
        print("âš ï¸ VÃ¡rios testes falharam. Verifique a configuraÃ§Ã£o e dependÃªncias.")
    
    return passed_tests == total_tests


if __name__ == "__main__":
    # Executa todos os testes
    success = asyncio.run(run_all_tests())

